{"title":"How can the social sciences benefit from knowledge graphs? <br>  Using Wikidata to examine the world’s billionaires","markdown":{"yaml":{"title":"How can the social sciences benefit from knowledge graphs? <br>  Using Wikidata to examine the world’s billionaires","author":"<br> Wealth Data Science Summer/Winter School 2024 <br> <br> Daria Tisch <br>  <br> Max-Planck-Institut für Gesellschaftsforschung","subtitle":"<br> July 2024","format":{"revealjs":{"theme":["default","custom.scss"],"preview-links":"auto","chalkboard":{"boardmarker-width":5}}},"editor":"visual","slide-number":"c","bibliography":"references.bib"},"headingText":"Introduction","containsRefs":true,"markdown":"\n\n\n::: columns\n::: {.column width=\"40%\"}\n![](pics/knowgraph.webp){.absolute top=\"100\" left=\"0\" width=\"350\"}\n:::\n\n::: {.column width=\"60%\"}\n-   What are knowlegde graphs?\n\n-   How can the social sciences benefit from knowledge graphs?\n\n-   Using Wikidata to study the superrich\n:::\n:::\n\n::: notes\n-   Have you ever wondered how Google seems to understand exactly what you're looking for, even if your search query is vague?\n\n-   The secret behind such intelligent search results lies in a technology called a knowledge graph. A knowledge graph is a structured representation of knowledge, where entities (such as people, places, or things) and their relationships are interconnected, much like a map of knowledge.\n\n-   Knowledge graphs are transforming how we access and interact with information. They power search engines, recommendation systems, virtual assistants\n\n-   SO how can social scientists benefit from knowlegde graphs?\\\n:::\n\n## Knowlege Graph: Bill Gates\n\nKnowledge graphs are defined as graphs of data that accumulate and convey knowledge of the real world. The nodes in knowledge graphs represent the entities of interest, and the edges represent the relations between the entities [@peng2023]\n\n![](pics/bill.png){fig-align=\"center\"} <https://explore.gnd.network/en/gnd/119081199/relations>\n\n::: notes\n-   These representations utilize formal semantics, which allows computers to process them efficiently and unambiguously. For example, the entity “Bill Gates\" can be linked to the entity “Microsoft\" because Bill Gates is the founder of Microsoft; thus, they have relationships in the real world.\n:::\n\n## Knowlege Graph: Elon Musk\n\n![](pics/musk.png){fig-align=\"center\"}\n\n<https://explore.gnd.network/en/gnd/1062481119/relations>\n\n::: notes\n-   sth\n:::\n\n## Wikidata as a knowledge graph\n\n::: columns\n::: {.column width=\"40%\"}\n![](pics/gates_wiki.png){fig-align=\"center\"}\n:::\n\n::: {.column width=\"60%\"}\n-   \"Wikidata is a free, collaborative, multilingual, secondary database, collecting structured data to provide support for Wikipedia, Wikimedia Commons, the other wikis of the Wikimedia movement, and to anyone in the world\"[@wikidata2023]\n\n-   Can be read and edited by both humans and machines.\n\n-   Centralized storage for the structured data of Wikimedia projects (e.g., Wikipedia)\n\n-   Each item in Wikidata is linked to various attributes and other items, allowing for complex queries and data extraction.\n:::\n:::\n\n## Wikidata Page: Bill Gates\n\n<iframe src=\"https://www.wikidata.org/wiki/Q5284\" width=\"100%\" height=\"500px\">\n\n</iframe>\n\n[Bill Gates](https://www.wikidata.org/wiki/Q5284)\n\n::: notes\n-   show different example quieries in the wikidata querie service\n-   occupation of Father of father of Bill Gates\n:::\n\n## Wikidata’s strengths for the social science\n\n-   Wikidata as content provider: provides structured, human- and machine-readable information on different topics → create data sets from structured data using the query language\\\n    SPARQL\n-   Wikidata as linked open data provider: Wikidata provides not only links within the Wikidata knowledge graph but also links to other databases via external identifiers (e.g., Twitter, ORCID, movie databases)\n-   Wikidata as a growing knowledge base: Social scientists may contribute to Wikidata by importing their data or linking their data to existing datasets (e.g., Comparative Legislators Database**)**\n-   Wikidata is multilingual: research without language barriers, named entity linking\n-   Wikidata is free: available for anyone to use, reuse, and redistribute\n\n::: notes\n-   For example, Wikidata entries about actresses can be\\\n    easily linked to their entries in movie databases. Or Wikidata entries of scientists can be\\\n    easily linked to their entries in the ORCID database (Seidlmayer et al. 2020). Individuals on\\\n    Wikidata can also be linked to their Twitter accounts or entries in different encyclopedias.\n-   \n:::\n\n## Caveats\n\n-   Accuracy of the data (e.g., biases of the editors)\n\n-   Missing information (e.g., gender, language, race biases [@wagner2015])\n\n::: notes\n-   mostly anonymous volunteers.\n-   accuracy of the data is not guaranteed, and the perspectives and biases of the editors might influence the information provided\n:::\n\n## Application: How to use Wikidata\n\n-   Use the language SPARQL to formulate questions (queries) for knowledge databases\n\n-   Wikidata Query Service (<https://query.wikidata.org/>)\n\n-   WikidataR is a read-write API client library for Wikidata [@shafee2022] (to send SPARQL queries to the Wikidata Query Service SPARQL endpoint)\n\n-   To learn writing SPARQL queries, Wikidata's tutorial page (<https://www.wikidata.org/wiki/Wikidata:SPARQL_tutorial>) and the examples at the Wikidata Query Service are helpful\n\n::: notes\n-   With the right database, a SPARQL query could answer questions like “what is the most popular tonality in music?” or “which character was portrayed by the most actors?” or “what’s the distribution of blood types?” or “which authors’ works entered the public domain this year?”.\n:::\n\n## Queries\n\n<iframe src=\"https://query.wikidata.org/\" width=\"100%\" height=\"500px\">\n\n</iframe>\n\n[Wikidata Query Service](https://query.wikidata.org/)\n\n::: notes\n-   show different example quieries in the wikidata querie service\n-   occupation of Father of father of Bill Gates\n:::\n\n## Query: What is the place of birth of Bill Gates' grandfather?\n\n<iframe src=\"https://w.wiki/AYt9\" width=\"100%\" height=\"500px\">\n\n</iframe>\n\n[Link to query](https://w.wiki/AYt9)\n\n::: notes\n-   place of birth of grandfather of Bill Gates\n:::\n\n## Query: How many employees does Bill Gates have?\n\n<iframe src=\"https://w.wiki/AYtT\" width=\"100%\" height=\"500px\">\n\n</iframe>\n\n[Link to query](https://w.wiki/AYtT)\n\n::: notes\n-   https://w.wiki/AYtT\n:::\n\n## The world’s billionaires on Wikidata\n\n-   Database: Forbes billionaires, 2010-2024\n\n-   N = 4504 billionaires\n\n-   Semi-automatically reconciled with Wikidata with the help of OpenRefine\n\n::: notes\n-   Forbes magazine publishes a list of US dollar billionaires every year. Based on the list from 2010 until 2022, a data set including all listed billionaires is generated. The final data set includes a unique identifier, name, gender, birth date, country of citizenship, highest rank, and maximum wealth (between 2010 and 2024)\n-   OpenRefine is an open-source tool for working with messy data and includes a reconciliation function. Reconciliation means that string values are matched to entities in Wikidata or other databases. The mapping of the billionaires' names to items in Wikidata was checked manually for all XXX individuals.\n:::\n\n## Coverage\n\n```{r}\n#| echo: false\n#| output: false\n\n# create vector with needed packages\npkgs <- c(\"xtable\", # to export dfs as e.g. latex tables\n              \"knitr\", # for dynamic reporting, e.g. saving tables\n              \"tidyverse\", # to prepare/tidy data,\n              \"ggplot2\", # for creating plots\n              \"sjPlot\", # for marginal effect plots\n              \"stargazer\", # for regression tables\n              \"WikipediR\", # recommended in method bites: wrapper for the MediaWiki API\n              # \"WikidataR\", # recommended in method bites: read, query, write wikidata, so this would be an alternative to SPARQL\n              \"pageviews\", # recommended in method bites: API client for Wikimedia traffic data\n              # \"networkD3\", # recommended in method bites: for creating network graphs\n              \"lubridate\", # recommended in method bites: parse date formats#\n              \"legislatoR\", # to understand the method bites article better\n          \"jtools\", # Visualizing regression model predictions\n          \"ggpubr\", # arrange ggplots\n          \"htmltools\"\n)\n\n# install missing packages\nlapply(pkgs[!(pkgs %in% installed.packages())], install.packages)\n\n# load packages\nlapply(pkgs, library, character.only = TRUE)\n\n# Set working directory\nSys.info()['nodename']\nwork_dir = ifelse(Sys.info()['nodename']==\"P2010\", \n                  \"C:/Users/ti/Local/seafile/main/---projects---/bill_wiki\",\n                  \"D:/Seafile/main/---projects---/bill_wiki\")\nsetwd(work_dir)\ngetwd()\nload(\"data_scraped/df_bill_wiki.RData\")\ndf = as.data.frame(df)\ndf = df %>%\n  mutate(d_wikidata = ifelse(is.na(id_wikidata), 0, 1),\n         d_wikipedia = ifelse(is.na(page_id), 0, 1),\n         birthyear = as.numeric(birthyear),\n         properties_count = as.numeric(properties_count),\n         gender = ifelse(gender == \"M\", \"Male\",\n                         ifelse(gender == \"F\", \"Female\", gender)))\n#* Coverage of billionaires\n\n\nworld <- map_data(\"world\") %>%\n  mutate(region = ifelse(subregion == \"Hong Kong\" & !is.na(subregion), \"Hong Kong\", region))\n\n\nmap <- df %>% \n  group_by(countryOfCitizenship) %>% \n  dplyr::summarise(n = n(),\n                   coverage = round(mean(d_wikidata) * 100, 2)\n  ) %>% \n  as.data.frame() %>%\n  ungroup() %>%\n  arrange(-n) %>%\n  mutate(region = countryOfCitizenship) %>%\n  select(-countryOfCitizenship)\n\n\n\n# rename country names to fit those of the \"world\" data\nmap$region[map$region == \"British Virgin Islands\"] <- \"Virgin Islands\"\nmap$region[map$region == \"Czechia\"] <- \"Czech Republic\"\nmap$region[map$region == \"Eswatini (Swaziland)\"] <- \"Swaziland\"\nmap$region[map$region == \"United Kingdom\"] <- \"UK\"\nmap$region[map$region == \"United States\"] <- \"USA\"\nmap$region[map$region == \"St. Kitts and Nevis\"] <- \"Nevis\"\n\n\n# merge \"world\" data with billionare frequencies\nworld_f <- left_join(world, map, by = \"region\")\n\nmap_coverage <- ggplot(data = world_f , aes(x = long, y = lat, group = group),\n                     size = 0.1) +\n  geom_polygon(aes(fill = coverage), color = \"black\") +\n  theme_void() +\n  scale_fill_gradient(\"Wikidata coverage\", low = \"darkblue\", \n                      high = \"lightblue\", na.value = \"white\") + \n  theme(legend.position = \"right\", \n        legend.title = element_text(size = 10),\n        legend.text = element_text(size = 10))\n\n\n\n# descriptives\ncols <- c('d_wikidata', 'd_wikipedia', \"properties_count\",\"languages_count\" )\ndescriptives = stargazer(\n  df[, cols], type = \"html\", \n  summary.stat = c(\"min\", \"max\", \"mean\", \"sd\", \"N\"),\n  covariate.labels = c(\"Wikidata (yes-no)\", \"English Wikipedia article (yes-no)\", \"Number of properties\",\n                       \"Number of Wikipedias (languages)\"))\n\n\n##### 2.2 Logistic regression on having a wikidata id/ page id  #####\n\n# create average effect plots for having a wikidata id\nglm_id_wikidata2 <- glm(d_wikidata ~ gender+birthyear+ \n                          continent +max_rank, \n                        family=binomial(link=logit),\n                        data=df)\n\np1 = plot_model(glm_id_wikidata2,type=\"pred\", terms = \"gender\", theme(classic),\n                axis.title = c( \"Gender\", \"Probability (Wikidata item)\") , title = \"\",\n                axis.lim = c(0,1)\n) \n\n\n#  age\np4 = plot_model(glm_id_wikidata2,type=\"pred\", terms = \"birthyear [all]\", theme(classic),\n                axis.title = c( \"Birthyear\", \"Probability (Wikidata item)\") , title = \"\",\n                axis.lim = c(0,1)\n) \n\n\n#  continent\np7 = plot_model(glm_id_wikidata2,type=\"pred\", terms = \"continent\", theme(classic),\n                axis.title = c( \"Continent\", \"Probability (Wikidata item)\") , title = \"\",\n                axis.lim = c(0,1) \n) +  theme(axis.text.x = element_text(angle=35, hjust=1))\n\n\n\n#  max_rank\np8 = plot_model(glm_id_wikidata2,type=\"pred\", terms = \"max_rank [all]\", theme(classic),\n                axis.title = c( \"Wealth rank (max)\", \"Probability (Wikidata item)\") , title = \"\",\n                axis.lim = c(0,1)\n)\n\n```\n\n```{r}\n#| echo: false\n#| output: true\nmap_coverage\n\n```\n\n::: notes\n-   sth\n:::\n\n## Descriptive statistics\n```{r}\n#| echo: false\n#| output: true\nbrowsable(HTML(descriptives))\n```\n::: notes\n-   \n:::\n\n## Who is covered?\n```{r}\n#| echo: false\n#| output: true\np1\n```\n::: notes\n-   \n:::\n\n## Who is covered?\n```{r}\n#| echo: false\n#| output: true\np8\n```\n::: notes\n-   \n:::\n\n## Who is covered?\n```{r}\n#| echo: false\n#| output: true\np4\n```\n::: notes\n-   \n:::\n\n\n## Who is covered?\n```{r}\n#| echo: false\n#| output: true\np7\n```\n::: notes\n-   \n:::\n\n\n## Network analysis: Family webs {.scrollable}\n\n```{r}\n#| echo: false\n#| output: false\nsource(\"../code/03_family_webs.R\")\n\n```\n\n```{r}\n#| echo: false\n#| output: true\nwidget_all\n\n```\n\n::: notes\n-   \n:::\n\n## Family webs with at least 5 billionaires {.scrollable}\n\n```{r}\n#| echo: false\n#| output: true\nwidget_5\n\n```\n\n::: notes\n-   \n:::\n\n## Family web with most billionaires (13) {.scrollable}\n\n```{r}\n#| echo: false\n#| output: true\np_fam_largest\n\n```\n\n::: notes\n-   \n:::\n\n## What can be done with Wikidata?\n\n-   Use to enrich own databases\n-   Publish own research data on Wikidata → good practice of open research data\n-   Connect to Wikipedia and analyse Wikipedia pages (e.g., content, page view, editing pages)\n-   Examining interconnections of different political and economic elites and / or elite institutions (or political parties, cultural organizations, companies)\n-   Genealogical data can be used to draw family webs\n\n::: notes\n-   \n:::\n\n## References\n\n::: {#refs}\n:::\n","srcMarkdownNoYaml":"\n\n## Introduction\n\n::: columns\n::: {.column width=\"40%\"}\n![](pics/knowgraph.webp){.absolute top=\"100\" left=\"0\" width=\"350\"}\n:::\n\n::: {.column width=\"60%\"}\n-   What are knowlegde graphs?\n\n-   How can the social sciences benefit from knowledge graphs?\n\n-   Using Wikidata to study the superrich\n:::\n:::\n\n::: notes\n-   Have you ever wondered how Google seems to understand exactly what you're looking for, even if your search query is vague?\n\n-   The secret behind such intelligent search results lies in a technology called a knowledge graph. A knowledge graph is a structured representation of knowledge, where entities (such as people, places, or things) and their relationships are interconnected, much like a map of knowledge.\n\n-   Knowledge graphs are transforming how we access and interact with information. They power search engines, recommendation systems, virtual assistants\n\n-   SO how can social scientists benefit from knowlegde graphs?\\\n:::\n\n## Knowlege Graph: Bill Gates\n\nKnowledge graphs are defined as graphs of data that accumulate and convey knowledge of the real world. The nodes in knowledge graphs represent the entities of interest, and the edges represent the relations between the entities [@peng2023]\n\n![](pics/bill.png){fig-align=\"center\"} <https://explore.gnd.network/en/gnd/119081199/relations>\n\n::: notes\n-   These representations utilize formal semantics, which allows computers to process them efficiently and unambiguously. For example, the entity “Bill Gates\" can be linked to the entity “Microsoft\" because Bill Gates is the founder of Microsoft; thus, they have relationships in the real world.\n:::\n\n## Knowlege Graph: Elon Musk\n\n![](pics/musk.png){fig-align=\"center\"}\n\n<https://explore.gnd.network/en/gnd/1062481119/relations>\n\n::: notes\n-   sth\n:::\n\n## Wikidata as a knowledge graph\n\n::: columns\n::: {.column width=\"40%\"}\n![](pics/gates_wiki.png){fig-align=\"center\"}\n:::\n\n::: {.column width=\"60%\"}\n-   \"Wikidata is a free, collaborative, multilingual, secondary database, collecting structured data to provide support for Wikipedia, Wikimedia Commons, the other wikis of the Wikimedia movement, and to anyone in the world\"[@wikidata2023]\n\n-   Can be read and edited by both humans and machines.\n\n-   Centralized storage for the structured data of Wikimedia projects (e.g., Wikipedia)\n\n-   Each item in Wikidata is linked to various attributes and other items, allowing for complex queries and data extraction.\n:::\n:::\n\n## Wikidata Page: Bill Gates\n\n<iframe src=\"https://www.wikidata.org/wiki/Q5284\" width=\"100%\" height=\"500px\">\n\n</iframe>\n\n[Bill Gates](https://www.wikidata.org/wiki/Q5284)\n\n::: notes\n-   show different example quieries in the wikidata querie service\n-   occupation of Father of father of Bill Gates\n:::\n\n## Wikidata’s strengths for the social science\n\n-   Wikidata as content provider: provides structured, human- and machine-readable information on different topics → create data sets from structured data using the query language\\\n    SPARQL\n-   Wikidata as linked open data provider: Wikidata provides not only links within the Wikidata knowledge graph but also links to other databases via external identifiers (e.g., Twitter, ORCID, movie databases)\n-   Wikidata as a growing knowledge base: Social scientists may contribute to Wikidata by importing their data or linking their data to existing datasets (e.g., Comparative Legislators Database**)**\n-   Wikidata is multilingual: research without language barriers, named entity linking\n-   Wikidata is free: available for anyone to use, reuse, and redistribute\n\n::: notes\n-   For example, Wikidata entries about actresses can be\\\n    easily linked to their entries in movie databases. Or Wikidata entries of scientists can be\\\n    easily linked to their entries in the ORCID database (Seidlmayer et al. 2020). Individuals on\\\n    Wikidata can also be linked to their Twitter accounts or entries in different encyclopedias.\n-   \n:::\n\n## Caveats\n\n-   Accuracy of the data (e.g., biases of the editors)\n\n-   Missing information (e.g., gender, language, race biases [@wagner2015])\n\n::: notes\n-   mostly anonymous volunteers.\n-   accuracy of the data is not guaranteed, and the perspectives and biases of the editors might influence the information provided\n:::\n\n## Application: How to use Wikidata\n\n-   Use the language SPARQL to formulate questions (queries) for knowledge databases\n\n-   Wikidata Query Service (<https://query.wikidata.org/>)\n\n-   WikidataR is a read-write API client library for Wikidata [@shafee2022] (to send SPARQL queries to the Wikidata Query Service SPARQL endpoint)\n\n-   To learn writing SPARQL queries, Wikidata's tutorial page (<https://www.wikidata.org/wiki/Wikidata:SPARQL_tutorial>) and the examples at the Wikidata Query Service are helpful\n\n::: notes\n-   With the right database, a SPARQL query could answer questions like “what is the most popular tonality in music?” or “which character was portrayed by the most actors?” or “what’s the distribution of blood types?” or “which authors’ works entered the public domain this year?”.\n:::\n\n## Queries\n\n<iframe src=\"https://query.wikidata.org/\" width=\"100%\" height=\"500px\">\n\n</iframe>\n\n[Wikidata Query Service](https://query.wikidata.org/)\n\n::: notes\n-   show different example quieries in the wikidata querie service\n-   occupation of Father of father of Bill Gates\n:::\n\n## Query: What is the place of birth of Bill Gates' grandfather?\n\n<iframe src=\"https://w.wiki/AYt9\" width=\"100%\" height=\"500px\">\n\n</iframe>\n\n[Link to query](https://w.wiki/AYt9)\n\n::: notes\n-   place of birth of grandfather of Bill Gates\n:::\n\n## Query: How many employees does Bill Gates have?\n\n<iframe src=\"https://w.wiki/AYtT\" width=\"100%\" height=\"500px\">\n\n</iframe>\n\n[Link to query](https://w.wiki/AYtT)\n\n::: notes\n-   https://w.wiki/AYtT\n:::\n\n## The world’s billionaires on Wikidata\n\n-   Database: Forbes billionaires, 2010-2024\n\n-   N = 4504 billionaires\n\n-   Semi-automatically reconciled with Wikidata with the help of OpenRefine\n\n::: notes\n-   Forbes magazine publishes a list of US dollar billionaires every year. Based on the list from 2010 until 2022, a data set including all listed billionaires is generated. The final data set includes a unique identifier, name, gender, birth date, country of citizenship, highest rank, and maximum wealth (between 2010 and 2024)\n-   OpenRefine is an open-source tool for working with messy data and includes a reconciliation function. Reconciliation means that string values are matched to entities in Wikidata or other databases. The mapping of the billionaires' names to items in Wikidata was checked manually for all XXX individuals.\n:::\n\n## Coverage\n\n```{r}\n#| echo: false\n#| output: false\n\n# create vector with needed packages\npkgs <- c(\"xtable\", # to export dfs as e.g. latex tables\n              \"knitr\", # for dynamic reporting, e.g. saving tables\n              \"tidyverse\", # to prepare/tidy data,\n              \"ggplot2\", # for creating plots\n              \"sjPlot\", # for marginal effect plots\n              \"stargazer\", # for regression tables\n              \"WikipediR\", # recommended in method bites: wrapper for the MediaWiki API\n              # \"WikidataR\", # recommended in method bites: read, query, write wikidata, so this would be an alternative to SPARQL\n              \"pageviews\", # recommended in method bites: API client for Wikimedia traffic data\n              # \"networkD3\", # recommended in method bites: for creating network graphs\n              \"lubridate\", # recommended in method bites: parse date formats#\n              \"legislatoR\", # to understand the method bites article better\n          \"jtools\", # Visualizing regression model predictions\n          \"ggpubr\", # arrange ggplots\n          \"htmltools\"\n)\n\n# install missing packages\nlapply(pkgs[!(pkgs %in% installed.packages())], install.packages)\n\n# load packages\nlapply(pkgs, library, character.only = TRUE)\n\n# Set working directory\nSys.info()['nodename']\nwork_dir = ifelse(Sys.info()['nodename']==\"P2010\", \n                  \"C:/Users/ti/Local/seafile/main/---projects---/bill_wiki\",\n                  \"D:/Seafile/main/---projects---/bill_wiki\")\nsetwd(work_dir)\ngetwd()\nload(\"data_scraped/df_bill_wiki.RData\")\ndf = as.data.frame(df)\ndf = df %>%\n  mutate(d_wikidata = ifelse(is.na(id_wikidata), 0, 1),\n         d_wikipedia = ifelse(is.na(page_id), 0, 1),\n         birthyear = as.numeric(birthyear),\n         properties_count = as.numeric(properties_count),\n         gender = ifelse(gender == \"M\", \"Male\",\n                         ifelse(gender == \"F\", \"Female\", gender)))\n#* Coverage of billionaires\n\n\nworld <- map_data(\"world\") %>%\n  mutate(region = ifelse(subregion == \"Hong Kong\" & !is.na(subregion), \"Hong Kong\", region))\n\n\nmap <- df %>% \n  group_by(countryOfCitizenship) %>% \n  dplyr::summarise(n = n(),\n                   coverage = round(mean(d_wikidata) * 100, 2)\n  ) %>% \n  as.data.frame() %>%\n  ungroup() %>%\n  arrange(-n) %>%\n  mutate(region = countryOfCitizenship) %>%\n  select(-countryOfCitizenship)\n\n\n\n# rename country names to fit those of the \"world\" data\nmap$region[map$region == \"British Virgin Islands\"] <- \"Virgin Islands\"\nmap$region[map$region == \"Czechia\"] <- \"Czech Republic\"\nmap$region[map$region == \"Eswatini (Swaziland)\"] <- \"Swaziland\"\nmap$region[map$region == \"United Kingdom\"] <- \"UK\"\nmap$region[map$region == \"United States\"] <- \"USA\"\nmap$region[map$region == \"St. Kitts and Nevis\"] <- \"Nevis\"\n\n\n# merge \"world\" data with billionare frequencies\nworld_f <- left_join(world, map, by = \"region\")\n\nmap_coverage <- ggplot(data = world_f , aes(x = long, y = lat, group = group),\n                     size = 0.1) +\n  geom_polygon(aes(fill = coverage), color = \"black\") +\n  theme_void() +\n  scale_fill_gradient(\"Wikidata coverage\", low = \"darkblue\", \n                      high = \"lightblue\", na.value = \"white\") + \n  theme(legend.position = \"right\", \n        legend.title = element_text(size = 10),\n        legend.text = element_text(size = 10))\n\n\n\n# descriptives\ncols <- c('d_wikidata', 'd_wikipedia', \"properties_count\",\"languages_count\" )\ndescriptives = stargazer(\n  df[, cols], type = \"html\", \n  summary.stat = c(\"min\", \"max\", \"mean\", \"sd\", \"N\"),\n  covariate.labels = c(\"Wikidata (yes-no)\", \"English Wikipedia article (yes-no)\", \"Number of properties\",\n                       \"Number of Wikipedias (languages)\"))\n\n\n##### 2.2 Logistic regression on having a wikidata id/ page id  #####\n\n# create average effect plots for having a wikidata id\nglm_id_wikidata2 <- glm(d_wikidata ~ gender+birthyear+ \n                          continent +max_rank, \n                        family=binomial(link=logit),\n                        data=df)\n\np1 = plot_model(glm_id_wikidata2,type=\"pred\", terms = \"gender\", theme(classic),\n                axis.title = c( \"Gender\", \"Probability (Wikidata item)\") , title = \"\",\n                axis.lim = c(0,1)\n) \n\n\n#  age\np4 = plot_model(glm_id_wikidata2,type=\"pred\", terms = \"birthyear [all]\", theme(classic),\n                axis.title = c( \"Birthyear\", \"Probability (Wikidata item)\") , title = \"\",\n                axis.lim = c(0,1)\n) \n\n\n#  continent\np7 = plot_model(glm_id_wikidata2,type=\"pred\", terms = \"continent\", theme(classic),\n                axis.title = c( \"Continent\", \"Probability (Wikidata item)\") , title = \"\",\n                axis.lim = c(0,1) \n) +  theme(axis.text.x = element_text(angle=35, hjust=1))\n\n\n\n#  max_rank\np8 = plot_model(glm_id_wikidata2,type=\"pred\", terms = \"max_rank [all]\", theme(classic),\n                axis.title = c( \"Wealth rank (max)\", \"Probability (Wikidata item)\") , title = \"\",\n                axis.lim = c(0,1)\n)\n\n```\n\n```{r}\n#| echo: false\n#| output: true\nmap_coverage\n\n```\n\n::: notes\n-   sth\n:::\n\n## Descriptive statistics\n```{r}\n#| echo: false\n#| output: true\nbrowsable(HTML(descriptives))\n```\n::: notes\n-   \n:::\n\n## Who is covered?\n```{r}\n#| echo: false\n#| output: true\np1\n```\n::: notes\n-   \n:::\n\n## Who is covered?\n```{r}\n#| echo: false\n#| output: true\np8\n```\n::: notes\n-   \n:::\n\n## Who is covered?\n```{r}\n#| echo: false\n#| output: true\np4\n```\n::: notes\n-   \n:::\n\n\n## Who is covered?\n```{r}\n#| echo: false\n#| output: true\np7\n```\n::: notes\n-   \n:::\n\n\n## Network analysis: Family webs {.scrollable}\n\n```{r}\n#| echo: false\n#| output: false\nsource(\"../code/03_family_webs.R\")\n\n```\n\n```{r}\n#| echo: false\n#| output: true\nwidget_all\n\n```\n\n::: notes\n-   \n:::\n\n## Family webs with at least 5 billionaires {.scrollable}\n\n```{r}\n#| echo: false\n#| output: true\nwidget_5\n\n```\n\n::: notes\n-   \n:::\n\n## Family web with most billionaires (13) {.scrollable}\n\n```{r}\n#| echo: false\n#| output: true\np_fam_largest\n\n```\n\n::: notes\n-   \n:::\n\n## What can be done with Wikidata?\n\n-   Use to enrich own databases\n-   Publish own research data on Wikidata → good practice of open research data\n-   Connect to Wikipedia and analyse Wikipedia pages (e.g., content, page view, editing pages)\n-   Examining interconnections of different political and economic elites and / or elite institutions (or political parties, cultural organizations, companies)\n-   Genealogical data can be used to draw family webs\n\n::: notes\n-   \n:::\n\n## References\n\n::: {#refs}\n:::\n"},"formats":{"revealjs":{"identifier":{"display-name":"RevealJS","target-format":"revealjs","base-format":"revealjs"},"execute":{"fig-width":10,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":false,"output":true,"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":true,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","html-math-method":{"method":"mathjax","url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML-full"},"slide-level":2,"to":"revealjs","output-file":"2024_knowgraph.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words"},"metadata":{"lang":"en","fig-responsive":false,"quarto-version":"1.4.553","auto-stretch":true,"title":"How can the social sciences benefit from knowledge graphs? <br>  Using Wikidata to examine the world’s billionaires","author":"<br> Wealth Data Science Summer/Winter School 2024 <br> <br> Daria Tisch <br>  <br> Max-Planck-Institut für Gesellschaftsforschung","subtitle":"<br> July 2024","editor":"visual","slideNumber":"c","bibliography":["references.bib"],"theme":["default","custom.scss"],"previewLinks":"auto","chalkboard":{"boardmarker-width":5}}}},"projectFormats":["revealjs"]}